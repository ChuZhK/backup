{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归（一）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">0) 介绍一些可能用到的numpy库的函数。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[1 2 3]\n",
      " [4 5 6]] \n",
      "\n",
      "B:\n",
      " [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]] \n",
      "\n",
      "C:\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#一些可能用到的numpy库的函数\n",
    "\n",
    "#创建numpy矩阵\n",
    "A = np.array([[1, 2, 3],[4, 5, 6]]) #创建矩阵\n",
    "B = np.ones((3, 2)) #创建全1矩阵\n",
    "C = np.zeros((3, 2)) #创建全0矩阵\n",
    "print('A:\\n',A,'\\n')\n",
    "print('B:\\n',B,'\\n')\n",
    "print('C:\\n',C,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\n",
      " [[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]] \n",
      "\n",
      "[[0 0]\n",
      " [2 0]] \n",
      "\n",
      "[[0]\n",
      " [0]\n",
      " [3]\n",
      " [0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#提取矩阵的某几行和某几列\n",
    "D = np.array([[1, 0, 0, 0],[0, 2, 0, 0],[0, 0, 3, 0],[0, 0, 0, 4]])\n",
    "print('D:\\n',D,'\\n')\n",
    "print(D[0:2, 1:3],'\\n') #提取矩阵的0-1行、1-2列的元素，返回一个2×2的矩阵\n",
    "print(D[:, 2:3],'\\n') #提取第2列上的所有元素，返回一个4×1的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\n",
      " [[3 2 1]\n",
      " [6 8 3]] \n",
      "\n",
      "The transpose of E:\n",
      " [[3 6]\n",
      " [2 8]\n",
      " [1 3]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵的转置\n",
    "E = np.array([[3,2,1],[6,8,3]])\n",
    "print('E:\\n',E,'\\n')\n",
    "print('The transpose of E:\\n',E.T,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\n",
      " [[0 1 1]\n",
      " [4 2 3]] \n",
      "\n",
      "G:\n",
      " [[0 8 1]\n",
      " [4 4 4]] \n",
      "\n",
      "F + G:\n",
      " [[0 9 2]\n",
      " [8 6 7]] \n",
      "\n",
      "F - G:\n",
      " [[ 0 -7  0]\n",
      " [ 0 -2 -1]] \n",
      "\n",
      "F * G:\n",
      " [[ 0  8  1]\n",
      " [16  8 12]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵的加/减/星乘(要求两个矩阵的行数相同、列数也相同)\n",
    "F = np.array([[0,1,1],[4,2,3]])\n",
    "G = np.array([[0,8,1],[4,4,4]])\n",
    "print('F:\\n',F,'\\n')\n",
    "print('G:\\n',G,'\\n')\n",
    "print('F + G:\\n',F + G,'\\n')\n",
    "print('F - G:\\n',F - G,'\\n')\n",
    "print('F * G:\\n',F * G,'\\n') #对应位置相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\n",
      " [[2 1 1]\n",
      " [9 2 3]] \n",
      "\n",
      "I:\n",
      " [[0 8]\n",
      " [4 4]\n",
      " [5 5]] \n",
      "\n",
      "H.dot(I):\n",
      " [[ 9 25]\n",
      " [23 95]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#矩阵点乘(注意前一个矩阵的列数要等于后一个矩阵的行数才能进行点乘)\n",
    "H = np.array([[2,1,1],[9,2,3]])\n",
    "I = np.array([[0,8],[4,4],[5,5]])\n",
    "print('H:\\n',H,'\\n')\n",
    "print('I:\\n',I,'\\n')\n",
    "print('H.dot(I):\\n',H.dot(I),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵(非奇异方阵)的求逆\n",
    "J = np.array([[1, 0, 0],[0, 2, 0],[0, 0, 3]])\n",
    "print('J:\\n',J,'\\n')\n",
    "print('The inverse of J:\\n',np.linalg.inv(J),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵的拼接\n",
    "K = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "L = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "print('K:\\n',K,'\\n')\n",
    "print('L:\\n',L,'\\n')\n",
    "print('\\n',np.r_[K, L],'\\n') #上下拼接\n",
    "print('\\n',np.c_[K, L],'\\n') #左右拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#矩阵的求和\n",
    "M = np.array([[5,0,2],[3,5,8]])\n",
    "print('M:\\n',M,'\\n')\n",
    "print('The sum of M:\\n',np.sum(M),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 使用pandas库的read_csv()函数(可以参考[pandas的官方文档](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html))将训练数据集'train.csv'和测试数据集'test.csv'载入到Dataframe对象中。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "#读取数据集\n",
    "#train_frame = pd.read_csv('train.csv')\n",
    "#test_frame = pd.read_csv('test.csv')\n",
    "\n",
    "#转化成numpy矩阵\n",
    "#train = np.array(train_frame)\n",
    "#test = np.array(test_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 假设模型为一元线性回归模型$\\hat{y}=wx+b$, 损失函数为$l(w,b)=\\frac{1}{2}\\sum_{i=1}^m(\\hat{y}^{(i)}-y^{(i)})^2$, 其中$\\hat{y}^{(i)}$表示第$i$个样本的预测值，$y^{(i)}$表示第$i$个样本的实际标签值, $m$为训练集中样本的个数。求出使得损失函数最小化的参数$w$和$b$。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法① \n",
    "\n",
    "将$l(w,b)$分别对$w$和$b$求导，得到\n",
    "$$\n",
    "\\frac{\\partial l(w,b)}{\\partial w}=w\\sum_{i=1}^m x_i^2 -\\sum_{i=1}^m (y_i-b)x_i,\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial l(w,b)}{\\partial b}=mb -\\sum_{i=1}^m (y_i-wx_i),\n",
    "$$\n",
    "令上述两式为零即可得到$w$和$b$的解析解：\n",
    "$$\n",
    "w=\\frac{\\sum_{i=1}^m y_i (x_i-\\bar{x})}{\\sum_{i=1}^m x_i^2-\\frac{1}{m}(\\sum_{i=1}^m x_i)^2},\n",
    "$$\n",
    "$$\n",
    "b=\\frac{1}{m}\\sum_{i=1}^m(y_i-wx_i),\n",
    "$$\n",
    "其中$\\bar{x}=\\frac{1}{m}\\sum_{i=1}^m x_i$为$x$的均值。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ever: 1.4742879639614397 \n",
      "\n",
      "w: 2.9884070446594273 \n",
      "\n",
      "b: 4.98431681257423 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法② 梯度下降法。(暂时不用实现)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法③ \n",
    "\n",
    "用矩阵表示，假设数据集有$m$个样本，特征有$n$维$。X=\\left[ \\begin{matrix} x_{11} & x_{12} & \\cdots & x_{1n} & 1 \\\\\n",
    "                         x_{21} & x_{22} & \\cdots & x_{2n} & 1 \\\\\n",
    "                         \\vdots & \\vdots &      & \\vdots & \\vdots \\\\\n",
    "                         x_{m1} & x_{m2} & \\cdots & x_{mn} & 1 \\end{matrix} \\right]$,\n",
    "        实际标签$Y=\\left[ \\begin{matrix} y_{1} \\\\\n",
    "                         y_{2} \\\\\n",
    "                         \\vdots \\\\\n",
    "                         y_{m}\\end{matrix} \\right]$,\n",
    "        参数$B=\\left[ \\begin{matrix} w_{1} \\\\\n",
    "                         w_{2} \\\\\n",
    "                         \\vdots \\\\\n",
    "                         w_{n} \\\\\n",
    "                         b\\end{matrix} \\right]$，则解析解为$B^*=(X^T X)^{-1}X^T Y$。推导过程可参考[这篇文章](https://zhuanlan.zhihu.com/p/74157986)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\n",
      " [3.04147887 4.90607366]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 使用求解出来的线性回归模型对测试数据集'test.csv'进行预测，输出可视化结果（比如用seaborn或者matplotlib等可视化库来画出测试数据的散点图以及训练好的模型函数图像）。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code here\n",
    "#A=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "#x = A[0, :] #从一个矩阵中提取出一行作为一个向量\n",
    "#y1 = np.array([2, 3, 5])\n",
    "#plt.plot(x, y1) #画出折线图\n",
    "#y2 = np.array([2.5, 2.8, 5.3])\n",
    "#plt.plot(x, y2, '.') #画出散点图\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 在训练数据集'train2.csv'上求一个三元线性回归模型$\\hat{y}=w_1 x_1 + w_2 x_2 + w_3 x_3 + b$的使得损失函数$l(w_1,w_2,w_3,b)=\\frac{1}{2}\\sum_{i=1}^m(\\hat{y}^{(i)}-y^{(i)})^2$最小的参数$w_1,w_2,w_3$以及$b$。并在测试数据集'test2.csv'上进行预测，输出预测结果的均方误差$MSE(\\hat{y},y)=\\frac{1}{n}\\sum^n_{i=1}(y^{(i)}-\\hat{y}^{(i)})^2$, $n$为测试集中样本个数。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法① 同2)中的方法③。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法② 梯度下降法。(暂时不用实现)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
