{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归（二）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 使用pandas库的read_csv()函数(可以参考[pandas的官方文档](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html))将训练数据集'train.csv'和测试数据集'test.csv'载入到Dataframe对象中。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "train_frame = pd.read_csv('train.csv')\n",
    "test_frame = pd.read_csv('test.csv')\n",
    "#读取数据集\n",
    "#train_frame = pd.read_csv('train.csv')\n",
    "#test_frame = pd.read_csv('test.csv')\n",
    "\n",
    "#转化成numpy矩阵\n",
    "train = np.array(train_frame)\n",
    "test = np.array(test_frame)\n",
    "print(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 假设模型为一元线性回归模型$\\hat{y}=wx+b$, 损失函数为$l(w,b)=\\frac{1}{2}\\sum_{i=1}^m(\\hat{y}^{(i)}-y^{(i)})^2$, 其中$\\hat{y}^{(i)}$表示第$i$个样本的预测值，$y^{(i)}$表示第$i$个样本的实际标签值, $m$为训练集中样本的个数。求出使得损失函数最小化的参数$w$和$b$。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法① \n",
    "\n",
    "将$l(w,b)$分别对$w$和$b$求导，得到\n",
    "$$\n",
    "\\frac{\\partial l(w,b)}{\\partial w}=w\\sum_{i=1}^m x_i^2 -\\sum_{i=1}^m (y_i-b)x_i,\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial l(w,b)}{\\partial b}=mb -\\sum_{i=1}^m (y_i-wx_i),\n",
    "$$\n",
    "令上述两式为零即可得到$w$和$b$的解析解：\n",
    "$$\n",
    "w=\\frac{\\sum_{i=1}^m y_i (x_i-\\bar{x})}{\\sum_{i=1}^m x_i^2-\\frac{1}{m}(\\sum_{i=1}^m x_i)^2},\n",
    "$$\n",
    "$$\n",
    "b=\\frac{1}{m}\\sum_{i=1}^m(y_i-wx_i),\n",
    "$$\n",
    "其中$\\bar{x}=\\frac{1}{m}\\sum_{i=1}^m x_i$为$x$的均值。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法② 梯度下降法。手动实现梯度下降法(不使用机器学习框架，如PyTorch、TensorFlow等)来进行模型的训练。算法步骤如下：(a)初始化模型参数$w$和$b$的值；(b)在负梯度的方向上更新参数(批量梯度下降($\\left|B\\right|=m$)、小批量随机梯度下降或者随机梯度下降($\\left|B\\right|=1$)均可)，并不断迭代这一步骤，更新公式(以小批量随机梯度下降为例)可以写成：$$w\\gets w-\\frac{\\eta}{\\left|B\\right|}\\sum_{i\\in{B}}x^{(i)}(wx^{(i)}+b-y^{(i)})$$, 和$$b\\gets b-\\frac{\\eta}{\\left|B\\right|}\\sum_{i\\in{B}}(wx^{(i)}+b-y^{(i)})$$， 其中$\\eta$表示学习率,$B$表示每次迭代中随机抽样的小批量，$\\left|B\\right|$则表示$B$中的样本数量。(c) 终止条件为迭代次数达到某一上限或者参数更新的幅度小于某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0775246918587285 4.730589887287296\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "x=train[:,0]\n",
    "y=train[:,1]\n",
    "\n",
    "w=0\n",
    "b=0\n",
    "eta=0.05\n",
    "base=0\n",
    "i=0\n",
    "while i<200 :\n",
    "        my_w=0\n",
    "        my_b=0\n",
    "        m=0\n",
    "        for g in range(len(train)):   #取出在步进范围内的训练值\n",
    "            my_x=train[g,0]\n",
    "            my_y=train[g,1]\n",
    "            if(my_x>base and my_x<base+eta):\n",
    "                my_w=my_x*(w*my_x+b-my_y)+my_w\n",
    "                my_b=w*my_x+b-my_y+my_b\n",
    "                m=m+1\n",
    "        if(m==0):\n",
    "            base=base+eta\n",
    "            i=i+1\n",
    "            continue\n",
    "#         print(i)\n",
    "        w=w-eta/m*my_w\n",
    "        b=b-eta/m*my_b\n",
    "        base=base+eta\n",
    "        i=i+1\n",
    "print(w,b)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方法③ \n",
    "\n",
    "用矩阵表示，假设数据集有$m$个样本，特征有$n$维$。X=\\left[ \\begin{matrix} x_{11} & x_{12} & \\cdots & x_{1n} & 1 \\\\\n",
    "                         x_{21} & x_{22} & \\cdots & x_{2n} & 1 \\\\\n",
    "                         \\vdots & \\vdots &      & \\vdots & \\vdots \\\\\n",
    "                         x_{m1} & x_{m2} & \\cdots & x_{mn} & 1 \\end{matrix} \\right]$,\n",
    "        实际标签$Y=\\left[ \\begin{matrix} y_{1} \\\\\n",
    "                         y_{2} \\\\\n",
    "                         \\vdots \\\\\n",
    "                         y_{m}\\end{matrix} \\right]$,\n",
    "        参数$B=\\left[ \\begin{matrix} w_{1} \\\\\n",
    "                         w_{2} \\\\\n",
    "                         \\vdots \\\\\n",
    "                         w_{n} \\\\\n",
    "                         b\\end{matrix} \\right]$，则解析解为$B^*=(X^T X)^{-1}X^T Y$。推导过程可参考[这篇文章](https://zhuanlan.zhihu.com/p/74157986)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 使用求解出来的线性回归模型对测试数据集'test.csv'进行预测，输出可视化结果（比如用seaborn或者matplotlib等可视化库来画出测试数据的散点图以及训练好的模型函数图像）。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13c5c434340>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "#A=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "#x = A[0, :] #从一个矩阵中提取出一行作为一个向量\n",
    "#y1 = np.array([2, 3, 5])\n",
    "#plt.plot(x, y1) #画出折线图\n",
    "#y2 = np.array([2.5, 2.8, 5.3])\n",
    "#plt.plot(x, y2, '.') #画出散点图\n",
    "#plt.show()\n",
    "t_x=test[:,0]\n",
    "t_y=test[:,1]\n",
    "m_y=[]\n",
    "for x in t_x:\n",
    "    m_y.append(w*x+b)\n",
    "plt.plot(t_x,m_y)\n",
    "plt.plot(t_x,t_y,'.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 在训练数据集'train2.csv'上求一个三元线性回归模型$\\hat{y}=w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3$的使得损失函数$l(w_0,w_1,w_2,w_3)=\\frac{1}{2}\\sum_{i=1}^m(\\hat{y}^{(i)}-y^{(i)})^2$最小的参数$w_0,w_1,w_2$以及$w_3$。并在测试数据集'test2.csv'上进行预测，输出预测结果的均方误差$MSE(\\hat{y},y)=\\frac{1}{n}\\sum^n_{i=1}(y^{(i)}-\\hat{y}^{(i)})^2$, $n$为测试集中样本个数。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法① 同2)中的方法③。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法② 类似2)中的方法②。算法步骤如下：(a)初始化模型参数$w_0,w_1,w_2,w_3$的值；(b)在负梯度的方向上更新参数(批量梯度下降($\\left|B\\right|=m$)、小批量随机梯度下降或者随机梯度下降($\\left|B\\right|=1$)均可)，并不断迭代这一步骤，更新公式(以小批量随机梯度下降为例)可以写成：$$w_j\\gets w_j-\\frac{\\eta}{\\left|B\\right|}\\sum_{i\\in{B}}x_j^{(i)}(w_0 + w_1 x_1^{(i)}+w_2 x_2^{(i)}+w_3 x_3^{(i)}-y^{(i)}), j=0,1,2,3$$, 其中$x_0^{(i)}=1$，$\\eta$表示学习率,$B$表示每次迭代中随机抽样的小批量，$\\left|B\\right|$则表示$B$中的样本数量。(c) 终止条件为迭代次数达到某一上限或者参数更新的幅度小于某个阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_0: 0.08983173553128751\n",
      "w_1: 1.6450248530257552\n",
      "w_2: 2.775048734800963\n",
      "w_3: 3.475045380431076\n",
      "MSE为：\n",
      "4.205406878653739\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "#\n",
    "#\n",
    "#\n",
    "#********************\n",
    "#运行此题的代码块请将变量刷新，直接从该题的代码块开始运行\n",
    "#*****************************\n",
    "#\n",
    "#\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#读取数据集\n",
    "train2_frame = pd.read_csv('train2.csv')\n",
    "test2_frame = pd.read_csv('test2.csv')\n",
    "\n",
    "#转化成numpy矩阵\n",
    "train2 = np.array(train2_frame)\n",
    "test2 = np.array(test2_frame)\n",
    "w_0=0\n",
    "w_1=0\n",
    "w_2=0\n",
    "w_3=0\n",
    "eta=0.05\n",
    "base=0\n",
    "i=0\n",
    "while i<300:\n",
    "    my_w_0=0\n",
    "    my_w_1=0\n",
    "    my_w_2=0\n",
    "    my_w_3=0\n",
    "    m_0=0\n",
    "    m_1=0\n",
    "    m_2=0\n",
    "    m_3=0\n",
    "    for g in range(len(train2)):\n",
    "        x0=1\n",
    "        x1=train2[g,0]\n",
    "        x2=train2[g,1]\n",
    "        x3=train2[g,2]\n",
    "        y=train2[g,3]\n",
    "        if(x0>base and x0<base+eta):\n",
    "            my_w_0=my_w_0+x0*(w_0+w_1*x1+w_2*x2+w_3*x3-y)\n",
    "            m_0=m_0+1\n",
    "        if(x1>base and x1<base+eta):\n",
    "            my_w_1=my_w_1+x1*(w_0+w_1*x1+w_2*x2+w_3*x3-y)\n",
    "            m_1=m_1+1\n",
    "        if(x2>base and x2<base+eta):\n",
    "            my_w_2=my_w_2+x2*(w_0+w_1*x1+w_2*x2+w_3*x3-y)\n",
    "            m_2=m_2+1\n",
    "        if(x3>base and x3<base+eta):\n",
    "            my_w_3=my_w_3+x3*(w_0+w_1*x1+w_2*x2+w_3*x3-y)\n",
    "            m_3=m_3+1\n",
    "    if (m_0 != 0):\n",
    "        w_0=w_0-eta/m_0*my_w_0\n",
    "    if m_1 !=0:\n",
    "        w_1=w_1-eta/m_1*my_w_1\n",
    "    if m_2 !=0:\n",
    "        w_2=w_2-eta/m_2*my_w_2\n",
    "    if m_3 !=0:\n",
    "        w_3=w_3-eta/m_3*my_w_3\n",
    "    base=base+eta\n",
    "    i=i+1\n",
    "print(\"w_0:\",w_0)\n",
    "print(\"w_1:\",w_1)\n",
    "print(\"w_2:\",w_2)\n",
    "print(\"w_3:\",w_3)\n",
    "t_x1=test2[:,0]\n",
    "t_x2=test2[:,1]\n",
    "t_x3=test2[:,2]\n",
    "t_y=test2[:,3]\n",
    "m_y=[]\n",
    "num=0\n",
    "p=0\n",
    "for u in range(len(t_x1)):\n",
    "    yy=w_0+w_1*t_x1[u]+w_2*t_x2[u]+w_3*t_x3[u]\n",
    "    num=(yy-t_y[u])*(yy-t_y[u])+num\n",
    "    m_y.append(yy)\n",
    "    p=p+1\n",
    "E=num/p\n",
    "print(\"MSE为：\")\n",
    "print(E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
