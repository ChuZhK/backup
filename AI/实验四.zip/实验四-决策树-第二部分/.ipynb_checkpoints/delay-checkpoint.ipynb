{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验四:决策树(2)</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验承接上次实验，用【ID3】算法实现一棵完整的决策树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 整理上次实验的代码，编写函数，【从属性集A中】寻找使得信息增益最大的属性   \n",
    "    输入：数据集D、属性集A   \n",
    "    输出：最佳划分的属性(维度)     \n",
    "    计算信息增益公式:  \n",
    "    某数据集D有若干特征值以及对应的标签值，其总样本大小为|D|,这里取其中一个特征类型feature,该特征包含V个不同的取值，特征值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^VD^v=|D|)$,则该特征值对应的信息增益为$$Gain(D,feature)=Ent(D)-\\sum_{v=1}^K \\frac{|D^v|}{D} Ent(D^v)$$</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算一个标签集的信息熵\n",
    "def entropy(label):\n",
    "    all = np.unique(label[:])\n",
    "    counter = Counter(label[:])\n",
    "    ent = 0\n",
    "    for a in all:\n",
    "        pk = counter[a] / len(label)\n",
    "        ent -= pk * math.log((pk), 2)\n",
    "    return ent\n",
    "\n",
    "\n",
    "\n",
    "#将属性集合按照dimension维度划分，返回划分后的属性集合和标签集和\n",
    "def split(feature, label, dimension):\n",
    "    dim = feature[:, dimension]    #取出属性集中被划分的维度\n",
    "    differ = np.unique(dim)        # differ为被划分属性上某一维度的非重复值数组\n",
    "    split_feature = []             #创建一个列表存储被划分的数据集\n",
    "    split_label = []               #创建一个列表存储被划分后的标签集\n",
    "    #遍历dimension维度上的非重复值\n",
    "    for x in differ:\n",
    "        small_feature = []\n",
    "        small_label = []\n",
    "        for i in range(len(dim)):\n",
    "            if (x == dim[i]):\n",
    "                q: list = feature[i, :]\n",
    "                w: list = label[i]\n",
    "                small_feature.append(q)\n",
    "                small_label.append(w)\n",
    "        split_feature.append(small_feature)\n",
    "        split_label.append(small_label)\n",
    "    return split_feature, split_label\n",
    "\n",
    "\n",
    "def best_split(D, A):\n",
    "    label:list=D[:,len(D[0,:])-1]\n",
    "    # feature=D[:,0:len(D)]\n",
    "    best_entropy = -1\n",
    "    best_dimension = 0\n",
    "    # print(\"in best_split:\",A)\n",
    "    # if len(A)==1:\n",
    "    #     return A[0]\n",
    "    for col in A:\n",
    "        d= entropy(label)\n",
    "        sp_feature, sp_label = split(D, label, col)\n",
    "        d_v=0\n",
    "        i=0\n",
    "        for arr in sp_label:\n",
    "            d_v -= len(arr) / len(label) * entropy(sp_label[i])\n",
    "            i+=1\n",
    "        if d_v + d > best_entropy:\n",
    "            best_entropy = d_v + d\n",
    "            best_dimension = col\n",
    "    return best_dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 完成DTree类中的TreeGenerate、train函数以完成决策树的构建。并完成DTree类中的predict函数来用构建好的决策树来对测试数据集进行预测并输出预测准确率。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树结点类\n",
    "class Node:\n",
    "    def __init__(self, isLeaf=True, label=-1, index=-1):\n",
    "        self.isLeaf = isLeaf # isLeaf表示该结点是否是叶结点\n",
    "        self.label = label # label表示该叶结点的label（当结点为叶结点时有用）\n",
    "        self.index = index # index表示该分支结点的划分属性的序号（当结点为分支结点时有用）\n",
    "        self.children = {} # children表示该结点的所有孩子结点，dict类型，方便进行决策树的搜索\n",
    "        \n",
    "    def addNode(self, val, node):\n",
    "        self.children[val] = node #为当前结点增加一个划分属性的值为val的孩子结点\n",
    "        self.isLeaf=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树类\n",
    "class DTree:\n",
    "    def __init__(self):\n",
    "        self.tree_root = None  # 决策树的根结点\n",
    "        self.possible_value = {}  # 用于存储每个属性可能的取值\n",
    "\n",
    "    '''\n",
    "    TreeGenerate函数用于递归构建决策树，伪代码参照课件中的“Algorithm 1 决策树学习基本算法”\n",
    "    '''\n",
    "\n",
    "    def TreeGenerate(self, D1, A):\n",
    "        D=np.array(D1)\n",
    "        # 生成结点 node\n",
    "        node = Node()\n",
    "        #取出最后一列作为标签集合\n",
    "        label:list = D[:,len(D[0, :]) - 1]\n",
    "        label_arr = np.array(label)\n",
    "        if (1 == len(np.unique(label_arr[:]))):\n",
    "            node.label = np.unique(label_arr)[0]\n",
    "            node.isLeaf=True\n",
    "            return node\n",
    "        label_mark = -1    #D中样本数量最多的标签类\n",
    "        Flag = True #当按照A中所存的维度进行索引属性值的时候，所有索引出来的属性值相同时flag的值为true\n",
    "        for i in A:\n",
    "            col=D[:,i]\n",
    "            col_differ=np.unique(col)\n",
    "            if len(col_differ)>1:\n",
    "                Flag=False\n",
    "        MAX = -1\n",
    "        differ_label = np.unique(label[:])\n",
    "        counter = Counter(label[:])\n",
    "        for l in differ_label:\n",
    "            num = counter[l]\n",
    "            if (num > MAX):\n",
    "                MAX = num\n",
    "                label_mark = l\n",
    "        if (len(A) == 0 or Flag):\n",
    "            node.label = label_mark\n",
    "            node.isLeaf=True\n",
    "            return node\n",
    "        a_star = best_split(D, A)\n",
    "        node.index=a_star\n",
    "        a_dimension = D[:, a_star]\n",
    "        a_strat_differ=self.possible_value[a_star]\n",
    "        for d in a_strat_differ:\n",
    "            lis: list = []\n",
    "            for i in range(len(D[:, 0])):\n",
    "                if (a_dimension[i] == d):\n",
    "                    tem:list=D[i,:]\n",
    "                    lis.append(tem)\n",
    "            if len(lis)==0:\n",
    "                new_nd=Node()\n",
    "                new_nd.isLeaf=True\n",
    "                new_nd.label=label_mark\n",
    "                node.addNode(d,new_nd)\n",
    "            else:\n",
    "                B: list = []\n",
    "                for x in A:\n",
    "                    if x == a_star:\n",
    "                        continue\n",
    "                    else:\n",
    "                        B.append(x)\n",
    "                new_node: Node = self.TreeGenerate(lis,B)\n",
    "                node.addNode(d, new_node)\n",
    "        return node\n",
    "\n",
    "    '''\n",
    "    train函数可以做一些数据预处理（比如Dataframe到numpy矩阵的转换，提取属性集等），并调用TreeGenerate函数来递归地生成决策树\n",
    "    '''\n",
    "\n",
    "    def train(self, D):\n",
    "        D = np.array(D)  # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        # A = set(range(D.shape[1] - 1)) # 属性集A\n",
    "        A: list = list(range(len(D[0, :]) - 1))\n",
    "        # 记下每个属性可能的取值\n",
    "        # A = np.array(A)\n",
    "        for every in A:\n",
    "            E: list = D[:, every]\n",
    "            self.possible_value[every] = np.unique(E)\n",
    "        self.tree_root = self.TreeGenerate(D, A)  # 递归地生成决策树，并将决策树的根结点赋值给self.tree_root\n",
    "\n",
    "        pass\n",
    "\n",
    "    '''\n",
    "    predict函数对测试集D进行预测， 并输出预测准确率（预测正确的个数 / 总数据数量）\n",
    "    '''\n",
    "\n",
    "    def search(self, node: Node, arr):\n",
    "        if node.isLeaf:\n",
    "            return node.label\n",
    "        else:\n",
    "            x = arr[node.index]\n",
    "            next1 = node.children[x]\n",
    "            return self.search(next1, arr)\n",
    "\n",
    "    def predict(self, D):\n",
    "        # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        pre = []\n",
    "        correct = 0\n",
    "        for i in range(len(D[:, 0])):\n",
    "            row = D[i, :]\n",
    "            predict = self.search(self.tree_root, row)\n",
    "            if predict == row[len(D[0,:]) - 1]:\n",
    "                correct += 1\n",
    "            pre.append(predict)\n",
    "        return (correct) / len(D[:, len(D[0,:]) - 1])\n",
    "\n",
    "        # 对于D中的每一行数据d，从当前结点x=self.tree_root开始，当当前结点x为分支结点时，\n",
    "        # 则搜索x的划分属性为该行数据相应的属性值的孩子结点（即x=x.children[d[x.index]]），不断重复，\n",
    "        # 直至搜索到叶结点，该叶结点的label就是数据d的预测label\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8415841584158416\n"
     ]
    }
   ],
   "source": [
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "dt = DTree()\n",
    "# 构建决策树\n",
    "train = np.array(train_frame)\n",
    "dt.train(train)\n",
    "# 利用构建好的决策树对测试数据集进行预测，输出预测准确率（预测正确的个数 / 总数据数量）\n",
    "test_frame = pd.read_csv('test_titanic.csv')\n",
    "test=np.array(test_frame)\n",
    "s=dt.predict(test)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可，如果交错请到讲台前联系助教，删掉之前的错误版本后再进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、这两周的实验课内容汇总到同一个实验报告中，于下周五实验课(4月1号前)上课前提交报告  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  \n",
    "4)每周的实验报告提交地址会变化，且有时间限制，提交时间为下周的实验课开始时，请注意及时提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验四(决策树)的实验报告上交地址:https://workspace.jianguoyun.com/inbox/collect/fdadf5486c654f4caf451e1d2c019c07/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DQlpUFYQp5WhChiS_q0E  \n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbKbP-AQp5WhChi1sa0E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
